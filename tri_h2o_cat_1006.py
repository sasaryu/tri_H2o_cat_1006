# -*- coding: utf-8 -*-
"""tri_H2O_cat_1006

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wUN_V4GAahxr9CaxzWqGCnGgQNLTo9XG
"""

!pip install pdpbox

# Google Driveのマウント
from google.colab import drive
drive.mount('/content/drive')

# 必要なライブラリをインポート
import pandas as pd
import numpy as np
from catboost import CatBoostClassifier
from sklearn.model_selection import KFold, cross_val_predict
from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, accuracy_score, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
import h2o
from h2o.automl import H2OAutoML

# Google Driveのファイルパスを指定してExcelファイルを読み込む
file_path = '/content/drive/My Drive/Colab Notebooks/tri_honban_analysis_final_data.xlsx'
data = pd.read_excel(file_path)

# NAを0に変換する変数
na_to_zero_cols = ['ph_ba', 'ph_chd', 'ph_chromo', 'ph_zaitaku', 'ph_epi', 'ph_transp_neop', 'hot']
data[na_to_zero_cols] = data[na_to_zero_cols].fillna(0)

# カテゴリ変数を適切にカテゴリ型に変換する
categorical_cols = ['year', 'month', 'wd', 'time_z', 'male', 'ambu', 'cov', 'syo_sai2', 'ref', 'hot', 'pat', 'tri', 'rr', 'cc_cat']
for col in categorical_cols:
    data[col] = data[col].astype(str)

# ターゲット変数と特徴量
y = data['adm']
features = list(set(na_to_zero_cols + categorical_cols + ['hr', 'rr', 'bt', 'sbp', 'crt', 'spo', 'age_month']))
X = data[features]

# --- CatBoostによる5-foldクロスバリデーション ---
kf = KFold(n_splits=5, shuffle=True, random_state=42)
catboost_model = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.1, loss_function='Logloss', verbose=0)

# クロスバリデーションによる予測
y_pred_proba_catboost = cross_val_predict(catboost_model, X, y, cv=kf, method='predict_proba')[:, 1]
y_pred_catboost = cross_val_predict(catboost_model, X, y, cv=kf)

# CatBoostの評価
auc_catboost = roc_auc_score(y, y_pred_proba_catboost)
f1_catboost = f1_score(y, y_pred_catboost)
accuracy_catboost = accuracy_score(y, y_pred_catboost)
print(f"CatBoost - AUC: {auc_catboost:.4f}, F1: {f1_catboost:.4f}, Accuracy: {accuracy_catboost:.4f}")

# CatBoostの混同行列
cm_catboost = confusion_matrix(y, y_pred_catboost)
cm_catboost_df = pd.DataFrame(cm_catboost, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'])
print("Confusion Matrix for CatBoost:")
print(cm_catboost_df)

# 特徴量重要度の可視化
catboost_model.fit(X, y, cat_features=categorical_cols)
feature_importances = catboost_model.get_feature_importance()
indices = np.argsort(feature_importances)[::-1]
plt.figure(figsize=(10, 6))
plt.title('Feature Importance (CatBoost)')
plt.barh(range(len(indices)), feature_importances[indices], align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.gca().invert_yaxis()
plt.xlabel('Feature Importance')
plt.show()

# --- H2Oによる5-foldクロスバリデーション ---
h2o.init()
h2o_df = h2o.H2OFrame(data)
h2o_df['adm'] = h2o_df['adm'].asfactor()

# H2O AutoMLの実行
aml = H2OAutoML(max_models=10, seed=1, nfolds=5)
aml.train(x=features, y='adm', training_frame=h2o_df)

# H2Oの最良モデルの選択
best_model = aml.leader
print("Best Model from H2O AutoML:")
print(best_model)

# H2Oの予測
h2o_test = h2o.H2OFrame(X)
y_pred_proba_h2o = best_model.predict(h2o_test).as_data_frame()['p1'].values
y_pred_h2o = best_model.predict(h2o_test).as_data_frame()['predict'].values

# H2Oの評価
auc_h2o = roc_auc_score(y, y_pred_proba_h2o)
f1_h2o = f1_score(y, y_pred_h2o)
accuracy_h2o = accuracy_score(y, y_pred_h2o)
print(f"H2O - AUC: {auc_h2o:.4f}, F1: {f1_h2o:.4f}, Accuracy: {accuracy_h2o:.4f}")

# H2Oの混同行列
cm_h2o = confusion_matrix(y, y_pred_h2o)
cm_h2o_df = pd.DataFrame(cm_h2o, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'])
print("Confusion Matrix for H2O:")
print(cm_h2o_df)

# --- ROC曲線の描画 ---
plt.figure(figsize=(10, 6))
fpr_catboost, tpr_catboost, _ = roc_curve(y, y_pred_proba_catboost)
fpr_h2o, tpr_h2o, _ = roc_curve(y, y_pred_proba_h2o)

plt.plot(fpr_catboost, tpr_catboost, label=f'CatBoost (AUC = {auc_catboost:.4f})')
plt.plot(fpr_h2o, tpr_h2o, label=f'H2O (AUC = {auc_h2o:.4f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

# H2Oのシャットダウン
h2o.shutdown(prompt=False)

# 特徴量重要度の可視化（CatBoost）
catboost_model.fit(X, y, cat_features=categorical_cols)
feature_importances_catboost = catboost_model.get_feature_importance()
indices_catboost = np.argsort(feature_importances_catboost)[::-1]
plt.figure(figsize=(10, 6))
plt.title('Feature Importance (CatBoost)')
plt.barh(range(len(indices_catboost)), feature_importances_catboost[indices_catboost], align='center')
plt.yticks(range(len(indices_catboost)), [features[i] for i in indices_catboost])
plt.gca().invert_yaxis()
plt.xlabel('Feature Importance')
plt.show()

# --- H2Oによる5-foldクロスバリデーション ---
h2o.init()
h2o_df = h2o.H2OFrame(data)
h2o_df['adm'] = h2o_df['adm'].asfactor()

# H2O AutoMLの実行
aml = H2OAutoML(max_models=10, seed=1, nfolds=5)
aml.train(x=features, y='adm', training_frame=h2o_df)

# H2Oの最良モデルの選択
best_model = aml.leader
print("Best Model from H2O AutoML:")
print(best_model)

# H2Oの予測
h2o_test = h2o.H2OFrame(X)
y_pred_proba_h2o = best_model.predict(h2o_test).as_data_frame()['p1'].values
y_pred_h2o = best_model.predict(h2o_test).as_data_frame()['predict'].values

# H2Oの評価
auc_h2o = roc_auc_score(y, y_pred_proba_h2o)
f1_h2o = f1_score(y, y_pred_h2o)
accuracy_h2o = accuracy_score(y, y_pred_h2o)
print(f"H2O - AUC: {auc_h2o:.4f}, F1: {f1_h2o:.4f}, Accuracy: {accuracy_h2o:.4f}")

# H2Oの混同行列
cm_h2o = confusion_matrix(y, y_pred_h2o)
cm_h2o_df = pd.DataFrame(cm_h2o, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'])
print("Confusion Matrix for H2O:")
print(cm_h2o_df)

# --- ROC曲線の描画 (CatBoostおよびH2Oの最良モデル) ---
plt.figure(figsize=(10, 6))
fpr_catboost, tpr_catboost, _ = roc_curve(y, y_pred_proba_catboost)
fpr_h2o, tpr_h2o, _ = roc_curve(y, y_pred_proba_h2o)

plt.plot(fpr_catboost, tpr_catboost, label=f'CatBoost (AUC = {auc_catboost:.4f})')
plt.plot(fpr_h2o, tpr_h2o, label=f'H2O Best Model (AUC = {auc_h2o:.4f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.grid()
plt.show()

# リーダーボードをデータフレームに変換
lb_df = aml.leaderboard.as_data_frame()

# 最良モデルがスタックドエンセmbleである場合の処理
if best_model.algo == "stackedensemble":
    # スタックドエンセmbleの次に良い個別モデルを選択
    for model_id in lb_df['model_id']:
        model = h2o.get_model(model_id)
        if model.algo != "stackedensemble":
            best_individual_model = model
            break
    print("Best individual model selected for feature importance:")
    print(best_individual_model)

    # 最良の個別モデルで特徴量重要度のプロット
    best_individual_model.varimp_plot()
else:
    # スタックドエンセmbleでなければ、そのままプロット
    best_model.varimp_plot()

# リーダーボードをデータフレームに変換
lb_df = aml.leaderboard.as_data_frame()

# 最良モデルがスタックドエンセmbleである場合の処理
if best_model.algo == "stackedensemble":
    # スタックドエンセmbleの次に良い個別モデルを選択
    for model_id in lb_df['model_id']:
        model = h2o.get_model(model_id)
        if model.algo != "stackedensemble":
            best_individual_model = model
            break
    print("Best individual model selected for feature importance:")
    print(best_individual_model)

    # 最良の個別モデルで特徴量重要度のプロット
    best_individual_model.varimp_plot()
else:
    # スタックドエンセmbleでなければ、そのままプロット
    best_model.varimp_plot()